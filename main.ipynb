{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123ae043",
   "metadata": {},
   "source": [
    "\n",
    "# Movie Recommendation System\n",
    "\n",
    "This notebook demonstrates the process of building a movie recommendation system by loading, cleaning, merging, and transforming movie datasets using Python. We will perform the following steps:\n",
    "1. Import necessary libraries.\n",
    "2. Load datasets.\n",
    "3. Select relevant columns.\n",
    "4. Handle missing values.\n",
    "5. Merge datasets.\n",
    "6. Convert JSON-like strings to lists.\n",
    "7. Extract specific information (e.g., director, cast names).\n",
    "8. Build the recommendation system using cosine similarity.\n",
    "9. Display the processed data and results.\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf9b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5150518e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Load datasets\n",
    "# Loading datasets containing movie credits, keywords, and metadata\n",
    "credits_df = pd.read_csv(\"credits.csv\")\n",
    "keywords_df = pd.read_csv(\"keywords.csv\")\n",
    "movies_metadata_df = pd.read_csv(\"movies_metadata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b93346",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Select relevant columns\n",
    "# We are only interested in a subset of columns from each dataset to reduce memory usage and focus on essential information\n",
    "movies_metadata_df = movies_metadata_df[['id', 'genres', 'original_title', 'overview', 'production_companies']]\n",
    "credits_df = credits_df[['id', 'cast', 'crew']]\n",
    "keywords_df = keywords_df[['id', 'keywords']]\n",
    "print(movies_metadata_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfdc2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Handle missing values\n",
    "# Checking for null values in each dataset to ensure data integrity\n",
    "print(movies_metadata_df.isnull().sum())\n",
    "print(credits_df.isnull().sum())\n",
    "print(keywords_df.isnull().sum())\n",
    "\n",
    "# Filling missing 'id' values with 0 and converting to numeric to prevent errors during merging\n",
    "movies_metadata_df['id'] = movies_metadata_df['id'].fillna(0)\n",
    "movies_metadata_df['id'] = pd.to_numeric(movies_metadata_df['id'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75cfe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Merge datasets\n",
    "# Merging datasets on 'id' column to combine all relevant information into a single DataFrame\n",
    "merged_df = keywords_df.merge(movies_metadata_df, on='id')\n",
    "merged_df = merged_df.merge(credits_df, on='id')\n",
    "\n",
    "# Filling missing JSON-like columns with empty lists to avoid issues during data processing\n",
    "merged_df['genres'] = merged_df['genres'].fillna('[]')\n",
    "merged_df['keywords'] = merged_df['keywords'].fillna('[]')\n",
    "merged_df['production_companies'] = merged_df['production_companies'].fillna('[]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f17c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Convert JSON-like strings to lists\n",
    "# Define a function to convert JSON-like strings to lists\n",
    "def convert_to_list(text):\n",
    "    elements_list = []\n",
    "    for element in ast.literal_eval(text):\n",
    "        elements_list.append(element['name'])\n",
    "    return elements_list\n",
    "\n",
    "# Apply the function to relevant columns to convert JSON-like strings into Python lists\n",
    "merged_df['genres'] = merged_df['genres'].apply(convert_to_list)\n",
    "merged_df['keywords'] = merged_df['keywords'].apply(convert_to_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a3032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Extract specific information\n",
    "# Define a function to extract director names from the 'crew' column\n",
    "def extract_director(crew_data):\n",
    "    director_list = []\n",
    "    for member in ast.literal_eval(crew_data):\n",
    "        if member['job'] == 'Director':\n",
    "            director_list.append(member['name'])\n",
    "            break\n",
    "    return director_list\n",
    "\n",
    "# Apply the function to extract directors\n",
    "merged_df['crew'] = merged_df['crew'].apply(extract_director)\n",
    "\n",
    "# Define a function to extract up to 5 cast names from the 'cast' column\n",
    "def extract_cast_names(cast_data):\n",
    "    cast_list = []\n",
    "    counter = 0\n",
    "    for member in ast.literal_eval(cast_data):\n",
    "        if counter < 5:\n",
    "            cast_list.append(member['name'])\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return cast_list\n",
    "\n",
    "# Apply the function to extract cast names\n",
    "merged_df['cast'] = merged_df['cast'].apply(extract_cast_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce1c95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 8: Build the recommendation system using cosine similarity\n",
    "# Combining all relevant text features into a single column for vectorization\n",
    "merged_df['combined_features'] = merged_df['genres'] + merged_df['keywords'] + merged_df['cast'] + merged_df['crew']\n",
    "merged_df['combined_features'] = merged_df['combined_features'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Vectorizing the combined features column\n",
    "vectorizer = CountVectorizer()\n",
    "count_matrix = vectorizer.fit_transform(merged_df['combined_features'])\n",
    "\n",
    "# Calculating the cosine similarity matrix\n",
    "cosine_sim_matrix = cosine_similarity(count_matrix, count_matrix)\n",
    "\n",
    "# Function to get movie recommendations based on cosine similarity\n",
    "def get_movie_recommendations(title, cosine_sim=cosine_sim_matrix):\n",
    "    idx = merged_df[merged_df['original_title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:11]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return merged_df['original_title'].iloc[movie_indices]\n",
    "\n",
    "# Example usage\n",
    "print(get_movie_recommendations('The Dark Knight'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3cbb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 9: Display the processed data\n",
    "# Display the first few rows of the processed DataFrame to verify the transformations\n",
    "merged_df.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
